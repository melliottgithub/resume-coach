{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import parsing\n",
    "import tiktoken\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_counter(text: str) -> int:\n",
    "    encoding = tiktoken.encoding_for_model('gpt-4o-mini')\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_str_file(file_path: str) -> str:\n",
    "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'marketing_sample_for_trulia_com-real_estate__20190901_20191031__30k_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30002 entries, 0 to 30001\n",
      "Data columns (total 30 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Job Title           30002 non-null  object \n",
      " 1   Job Description     30002 non-null  object \n",
      " 2   Job Type            0 non-null      float64\n",
      " 3   Categories          0 non-null      float64\n",
      " 4   Location            30002 non-null  object \n",
      " 5   City                30002 non-null  object \n",
      " 6   State               30002 non-null  object \n",
      " 7   Country             30002 non-null  object \n",
      " 8   Zip Code            16252 non-null  object \n",
      " 9   Address             0 non-null      float64\n",
      " 10  Salary From         0 non-null      float64\n",
      " 11  Salary To           0 non-null      float64\n",
      " 12  Salary Period       0 non-null      float64\n",
      " 13  Apply Url           18392 non-null  object \n",
      " 14  Apply Email         0 non-null      float64\n",
      " 15  Employees           0 non-null      float64\n",
      " 16  Industry            0 non-null      float64\n",
      " 17  Company Name        30000 non-null  object \n",
      " 18  Employer Email      0 non-null      float64\n",
      " 19  Employer Website    0 non-null      float64\n",
      " 20  Employer Phone      0 non-null      float64\n",
      " 21  Employer Logo       18708 non-null  object \n",
      " 22  Companydescription  19662 non-null  object \n",
      " 23  Employer Location   3348 non-null   object \n",
      " 24  Employer City       3316 non-null   object \n",
      " 25  Employer State      3316 non-null   object \n",
      " 26  Employer Country    30002 non-null  object \n",
      " 27  Employer Zip Code   1743 non-null   object \n",
      " 28  Uniq Id             30002 non-null  object \n",
      " 29  Crawl Timestamp     30002 non-null  object \n",
      "dtypes: float64(12), object(18)\n",
      "memory usage: 6.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Uniq Id is unique'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 'Uniq Id' column is unique\n",
    "'Uniq Id is unique' if df['Uniq Id'].nunique() == df.shape[0] else 'Uniq Id is not unique'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty columns\n",
    "df.dropna(axis=1, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30002 entries, 0 to 30001\n",
      "Data columns (total 18 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Job Title           30002 non-null  object\n",
      " 1   Job Description     30002 non-null  object\n",
      " 2   Location            30002 non-null  object\n",
      " 3   City                30002 non-null  object\n",
      " 4   State               30002 non-null  object\n",
      " 5   Country             30002 non-null  object\n",
      " 6   Zip Code            16252 non-null  object\n",
      " 7   Apply Url           18392 non-null  object\n",
      " 8   Company Name        30000 non-null  object\n",
      " 9   Employer Logo       18708 non-null  object\n",
      " 10  Companydescription  19662 non-null  object\n",
      " 11  Employer Location   3348 non-null   object\n",
      " 12  Employer City       3316 non-null   object\n",
      " 13  Employer State      3316 non-null   object\n",
      " 14  Employer Country    30002 non-null  object\n",
      " 15  Employer Zip Code   1743 non-null   object\n",
      " 16  Uniq Id             30002 non-null  object\n",
      " 17  Crawl Timestamp     30002 non-null  object\n",
      "dtypes: object(18)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['United States'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique country values\n",
    "df['Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State\n",
       "Oklahoma         1\n",
       "Home Based       1\n",
       "Sydney NSW       1\n",
       "Nevada           1\n",
       "BC               1\n",
       "              ... \n",
       "IL            1472\n",
       "FL            1550\n",
       "NY            2075\n",
       "TX            2466\n",
       "CA            4495\n",
       "Name: count, Length: 81, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['State'].value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json file usa_states.json\n",
    "usa_states = json.loads(read_str_file('usa_states.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CA', 'GA', 'IL', 'MO', 'IA', 'N/A', 'WA', 'NC', 'NY', 'TX', 'ID',\n",
       "       'FL', 'ME', 'OH', 'VA', 'MD', 'MA', 'NH', 'MI', 'CO', 'NJ', 'OR',\n",
       "       'OK', 'WY', 'AZ', 'CT', 'WI', 'AR', 'PA', 'SC', 'KY', 'MN', 'IN',\n",
       "       'NV', 'MT', 'AL', 'UT', 'RI', 'KS', 'TN', 'AK', 'SD', 'NM', 'NE',\n",
       "       'WV', 'MS', 'VT', 'HI', 'DE', 'LA', 'ND'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary from usa_states for quick lookup\n",
    "state_dict = {state['name']: state['abbreviation'] for state in usa_states}\n",
    "\n",
    "# Function to replace state names with abbreviations or 'N/A'\n",
    "def fix_state_values(state):\n",
    "    if state in state_dict:\n",
    "        return state_dict[state]\n",
    "    elif state in state_dict.values():\n",
    "        return state\n",
    "    else:\n",
    "        return 'N/A'\n",
    "\n",
    "# Apply the function to the State column\n",
    "df['State'] = df['State'].apply(fix_state_values)\n",
    "df['State'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Crawl Timestamp'] = pd.to_datetime(df['Crawl Timestamp'], format='%Y-%m-%d %H:%M:%S %z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2019-08-16 11:27:08+0000', tz='UTC'),\n",
       " Timestamp('2019-10-25 23:16:50+0000', tz='UTC'))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Crawl Timestamp'].min(), df['Crawl Timestamp'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Token analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate tokens in 'Job Description'\n",
    "df['tokens'] = df['Job Description'].apply(token_counter)\n",
    "df['tokens_markdown'] = df['Job Description'].apply(lambda x: token_counter(parsing.html_to_markdown(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_markdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30002.000000</td>\n",
       "      <td>30002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>978.270349</td>\n",
       "      <td>770.791247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>419.160302</td>\n",
       "      <td>338.428856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>906.000000</td>\n",
       "      <td>717.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1189.000000</td>\n",
       "      <td>950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>1472.000000</td>\n",
       "      <td>1180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>1699.000000</td>\n",
       "      <td>1349.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>2350.980000</td>\n",
       "      <td>1811.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6918.000000</td>\n",
       "      <td>4511.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tokens  tokens_markdown\n",
       "count  30002.000000     30002.000000\n",
       "mean     978.270349       770.791247\n",
       "std      419.160302       338.428856\n",
       "min       62.000000         0.000000\n",
       "50%      906.000000       717.000000\n",
       "75%     1189.000000       950.000000\n",
       "90%     1472.000000      1180.000000\n",
       "95%     1699.000000      1349.000000\n",
       "99%     2350.980000      1811.990000\n",
       "max     6918.000000      4511.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['tokens', 'tokens_markdown']].describe(percentiles=[0.75, 0.9, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['tokens_markdown'] == 0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saved clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30001 rows exported to data_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "df_export = df[df['tokens_markdown'] > 0]\n",
    "df_export.drop(columns=['tokens', 'tokens_markdown']).to_csv('data_cleaned.csv', index=False)\n",
    "print(df_export.shape[0], 'rows exported to data_cleaned.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
